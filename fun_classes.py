# system
import logging
import os
import os.path
import sys
import os
sys.path.append('../')
os.environ['KMP_DUPLICATE_LIB_OK']='True'
sys.path.append('../')

# data
import pandas as pd
import tpqoa
from datetime import datetime, timedelta
import numpy as np
import pickle

# display
import matplotlib
if __name__ == "__main__":
    matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# keras
from models.model import set_seeds
from tensorflow import keras

# project modules
import configs.config as cfg
import models.model as m
import common.utils as u
from  strategies.strategies import Strategy_1


################################ OaNDa (ond) base class #########################################
class ond: # Todo: should be abstract class?
    '''
    Base class for classes directly communicating to Oanda service
    '''
    def __init__(self,conf_file,  # oanda user conf file: todo: should I set it here??
                 instrument_file): # instrument conf file

        self.instrument_file = instrument_file
        self.instrument = instrument_file.instrument
        self.labels = instrument_file.labels  # "dir", "profit_over_spread", "loss_over_spread"]
        self.features = instrument_file.features
        self.lags = instrument_file.lags

        self.namefiles_dict = {}
        self.namefiles_dict = u.creates_filenames_dict(
            self.instrument_file.instrument,
            self.namefiles_dict, cfg)

        return

################################ Get DaTa (gdt) class #########################################
class gdt(ond):
    '''
    Class that inherits from class, dedicated to get historical data, create features and
    create the 3 datasets.
    Main methods are:
        self.get_most_recent(granul, days)
        self.make_features()
        self.make_lagged_features(lags)
        self.resample_data(barlength)
        self.make_3_datasets()
        self.standardize()
        self.save_to_file()
    '''

    def __init__(self,
                 conf_file, # Oanda conf file
                 instrument_file):  # instrument conf file

        super(gdt, self).__init__(instrument_file, conf_file)

        # raw tick data, and resampled version which has precise time interval
        self.raw_data = None
        self.raw_data_featured = None
        self.raw_data_featured_resampled = None

        # 3 datasets as generated by the division of raw_data_resampled, but not standardized
        # these datasets contain however labelling information that should be used, due to the fact
        # that standardization affects their value as well
        self.train_ds = None
        self.validation_ds = None
        self.test_ds = None

        # 3 datasets obtained from the 3 above via standardization.
        # Labelling values for market direction are not to be taken from here
        self.train_ds_std = None
        self.validation_ds_std = None
        self.test_ds_std = None

        # dict to host mu and std for all features, computed on training data
        self.params = {}

        # tpqoa object to download historical data
        self.api_oanda = tpqoa.tpqoa(conf_file)

        self.datalist = {"raw_data"                   : self.raw_data,
                         "raw_data_featured_resampled": self.raw_data_featured_resampled,
                         "train_ds_std"               : self.train_ds_std,
                         "validation_ds_std"          : self.validation_ds_std,
                         "test_ds_std"                : self.test_ds_std}

        gdt.check_create_path(self.namefiles_dict)

        return

    @classmethod
    def check_create_path(cls, namefiles_dict):
        if os.path.exists(namefiles_dict["base_data_folder_name"]):
            logging.info("__init__: Base folder exists: you may be overwriting existing files!")
            # Todo add choice to break out?
        else:
            logging.info("__init__: Non existent Base folder: creating it...")
            os.mkdir(namefiles_dict["base_data_folder_name"])
            os.mkdir(namefiles_dict["train_folder"])
            os.mkdir(namefiles_dict["valid_folder"])
            os.mkdir(namefiles_dict["test_folder"])

    @classmethod
    def _load_data_from_file(cls, namefiles_dict):
        '''load raw data and process data from file'''

        # raw data
        raw_data = pd.read_csv(
            namefiles_dict["raw_data_file_name"], index_col="time", parse_dates=True, header=0)
        raw_data_featured_resampled = pd.read_csv(
            namefiles_dict["raw_data_featured_resampled_file_name"], index_col="time", parse_dates=True, header=0)

        # loading 3 datasets, standardized, which contains also the columns for labels
        train_ds_std = \
            pd.read_csv(namefiles_dict["train_filename"], index_col="time", parse_dates=True, header=0)
        validation_ds_std = \
            pd.read_csv(namefiles_dict["valid_filename"], index_col="time", parse_dates=True, header=0)
        test_ds_std = \
            pd.read_csv(namefiles_dict["test_filename"], index_col="time", parse_dates=True, header=0)

        # normalization params
        params = pickle.load(open(namefiles_dict["train_folder"]  + "params.pkl", "rb"))

        return raw_data, raw_data_featured_resampled, train_ds_std, validation_ds_std, \
                    test_ds_std, params

    def load_data_from_file(self):
        self.raw_data, \
        self.raw_data_featured_resampled,\
        self.train_ds_std, \
        self.validation_ds_std,\
        self.test_ds_std,\
        self.params = gdt._load_data_from_file(self.namefiles_dict)
        return

    def report(self):
        '''provides insights on data memorized in the odc object'''
        for k, df in self.datalist.items():
            if df is not None:
                print("\nreport: Display info for dataframe {}".format(k))
                df.info()
                print("\n")
            else:
                print("\nreport: Dataframe {} is None".format(k))
        print("\nreport: displaying information about training set statistics")
        print("report: params is {}".format(self.params))
        return

    def get_most_recent(self, granul="S5", days = 2): #S5
        '''
        Get the most recent data for the instrument for which the object was created
        :param granul: base frequency for raw data being downloaded
        :param days: number of past days (from today) we are downloading data for
        '''
        # set start and end date for historical data retrieval
        now = datetime.utcnow()
        now = now - timedelta(microseconds = now.microsecond)
        past = now - timedelta(days = days)

        ask_df = pd.DataFrame()
        bid_df = pd.DataFrame()
        # get historical data up to now
        logging.info("get_most_recent: getting historical data from Oanda... ")
        ask_df = self.api_oanda.get_history(
                                    instrument = self.instrument,
                                    start = past,
                                    end = now,
                                    granularity = granul,
                                    price = "A",
                                    localize = False).c.dropna().to_frame()
        bid_df = self.api_oanda.get_history(
                                    instrument = self.instrument,
                                    start = past,
                                    end = now,
                                    granularity = granul,
                                    price = "B",
                                    localize = False).c.dropna().to_frame()

        # combine price information to derive the spread
        for p in "ohlc":
            print(p)
            self.raw_data['sprd_{}'.format(p)] = ask_df['{}'.format(p)] - \
                                                 bid_df['{}'.format(p)]
            self.raw_data['ask_{}'.format(p)] = ask_df['{}'.format(p)]
            self.raw_data['bid_{}'.format(p)] = bid_df['{}'.format(p)]
        self.raw_data['volume'] = ask_df["volume"]
        self.raw_data['c'] = (ask_df["c"] + ask_df['c'])/2
        self.raw_data.rename(columns={"c": self.instrument}, inplace=True)

        # output info on the data so obtained
        print("get_most_recent: self.raw_data.info() ", self.raw_data.info())

        # check for any missing data: TODO: is this useful here??
        assert (not self.raw_data.isnull().values.any()), \
            "get_most_recent: 1-NANs in self.raw_data_featured" #
        return

    def make_features(self, window = 10, sma_int=5, half_spread=0.00007):
        '''
        creates features using utils.make_features
        '''
        df = self.raw_data.copy()
        ref_price = self.instrument

        # Todo: do this check better
        assert (len(df[ref_price]) > sma_int), \
            "make_features: the dataframe length is not greater than the Simple Moving Average interval"
        assert (len(df[ref_price]) > window), \
            "make_features: the dataframe length is not greater than the Bollinger window"

        # Creating features from ref_price
        self.raw_data_featured = u.make_features(df, sma_int, window, half_spread, ref_price=ref_price )
        # TODO: make features should be enriched of other features, not only those obtained from single ref_price value!

        logging.info("make_features: created new features and added to self.raw_data_featured")
        print("make_features: self.raw_data_featured.columns ", self.raw_data_featured.columns)
        assert (not self.raw_data_featured.isnull().values.any()), \
            "make_features: 1-NANs in self.raw_data_featured"
        return

    def make_lagged_features(self, lags=5):
        '''
        Add lagged features to data.
        Creates features using utils.make_lagged_features
        '''
        assert (not self.raw_data_featured.isnull().values.any()), \
            "make_lagged_features: 1-NANs in self.raw_data_featured"

        # Creating lagged features, not based only on reference price but on the list self.features
        self.raw_data_featured = \
            u.make_lagged_features(self.raw_data_featured, self.features,lags=lags)

        assert (not self.raw_data_featured.isnull().values.any()), \
            "make_lagged_features: 2-NANs in self.raw_data_featured"
        logging.info("make_lagged_features: created new features and added to self.raw_data_featured")
        return

    def resample_data(self,  brl="1min"):
        '''
        Resample data already obtained to the frequency defined by brl
        :param brl: default 1min
        '''
        print("SEQUENCE: resample_data")
        bar_length = pd.to_timedelta(brl)
        # resampling data at the desired bar length,
        # holding the last value of the bar period (.last())
        # label right is to set the index to the end of the bar time
        # dropna is here to remove weekends.
        # iloc to remove the last bar/row typically incomplete
        assert (not self.raw_data_featured.isnull().values.any()), \
            "resample_data: 1-NANs in self.raw_data_featured"

        # Actual resampling of data
        self.raw_data_featured_resampled = \
            self.raw_data_featured.resample(bar_length,
                            label = "right").last().dropna().iloc[:-1] #TODO: review what -1 is here for!!

        assert (not self.raw_data_featured.isnull().values.any()), \
            "resample_data: 2-NANs in self.raw_data_featured"
        assert (not self.raw_data_featured_resampled.isnull().values.any()), \
            "resample_data: 2-NANs in self.raw_data_featured_resampled"
        logging.info("resample_data: resampled the just created new features, into self.raw_data_featured_resampled")
        return

    def make_3_datasets(self, split_pcs=(0.7, 0.10, 0.20)):
        '''
        Generate 3 datasets for ML training/evaluation/test and save to files.
        '''
        if self.raw_data_featured_resampled is not None:  # it was populated in precedence
            df = self.raw_data_featured_resampled
        else:
            logging.info("make_3_datasets: ERROR: self.raw_data_featured_resampled was empty!")
            exit()
        assert (sum(split_pcs) == 1), "make_3_datasets: split points are not dividing the unity"
        assert (not self.raw_data_featured_resampled.isnull().values.any()), \
            "make_3_datasets: NANs in self.raw_data_featured_resampled"

        # Making 3 datasets
        train_split = int(len(df) * split_pcs[0])
        val_split = int(len(df) * (split_pcs[0] + split_pcs[1]))
        self.train_ds = df.iloc[:train_split].copy()
        self.validation_ds = df.iloc[train_split:val_split].copy()
        self.test_ds = df.iloc[val_split:].copy()

        print("make_3_datasets: self.train_ds.info() ", self.train_ds.info())
        return

    def standardize(self):
        '''
        standardize the 3 datasets, using mean and std from train dataset
        to be called after make_3_datasets
        '''
        logging.info("standardize: subtracting mean and dividing by standard deviation, for each feature!")

        # Standardization of all columns in the 3 datasets using mean, std, from train data
        mu, std = self.train_ds.mean(), self.train_ds.std()
        self.params = {"mu": mu, "std": std}
        self.train_ds_std = (self.train_ds - mu) / std
        self.validation_ds_std = (self.validation_ds - mu) / std
        self.test_ds_std = (self.test_ds - mu) / std

        print("standardize: self.train_ds_std.info() ", self.train_ds_std.info())
        assert (not self.train_ds_std.isnull().values.any()), "standardize: NANs in Training Data"
        return

    def save_to_file(self):
        '''Save the previously formed datasets to disk'''

        # Saving each generated data file to disk
        self.raw_data.to_csv(self.namefiles_dict["raw_data_file_name"],
                             index = True, header=True)
        self.raw_data_featured_resampled.to_csv(
            self.namefiles_dict["raw_data_featured_resampled_file_name"],
                             index = True, header=True)

        self.train_ds_std.to_csv(self.namefiles_dict["train_filename"],
                             index = True, header=True)
        self.validation_ds_std.to_csv(self.namefiles_dict["valid_filename"],
                             index = True, header=True)
        self.test_ds_std.to_csv(self.namefiles_dict["test_filename"],
                             index = True, header=True)

        self.train_ds[self.labels].to_csv(self.namefiles_dict["train_labl_filename"],
                             index = True, header=True)
        self.validation_ds[self.labels].to_csv(self.namefiles_dict["valid_labl_filename"],
                             index = True, header=True)
        self.test_ds[self.labels].to_csv(self.namefiles_dict["test_labl_filename"],
                             index = True, header=True)

        pickle.dump(self.params, open(self.namefiles_dict["train_folder"]  + "params.pkl", "wb"))

        logging.info("save_to_file: Saved raw data and resampled raw data to {} and to {}".format(
                self.namefiles_dict["raw_data_file_name"],
                  self.namefiles_dict["raw_data_featured_resampled_file_name"]))
        logging.info('saved_to_file: saving params to file {}'.format(
            self.namefiles_dict["train_folder"]  + "params.pkl"))
        return


################################ TRaiNer (trn) class #########################################
class trn(ond):
    '''
    Class that inherits from class, dedicated to traind ML models on data obtained by gdt objects
    create the 3 datasets.
    Main methods are:
        TBD...
    '''

    def __init__(self,
                 conf_file, # Oanda conf file
                 instrument_file,  # instrument conf file
                 model_id):

        super(trn, self).__init__(instrument_file, conf_file)

        assert model_id in m.available_models, \
            "DL_Trainer: init: model_id not among known models"
        self.model_id = model_id

        self.model = None
        self.train_data = None
        self.test_data = None
        self.validation_data = None
        self.validation_labels = None
        self.train_labels = None
        self.test_labels = None
        self.lagged_cols = []
        self.lagged_cols_reordered = []
        return

    def load_train_data(self):
        assert os.path.exists(self.namefiles_dict["base_data_folder_name"]), \
            "Base data folder DO NOT exists!"
        self.train_data = pd.read_csv(self.namefiles_dict["train_filename"],
                                   index_col="time", parse_dates=True, header=0)
        self.test_data = pd.read_csv(self.namefiles_dict["test_filename"],
                                   index_col="time", parse_dates=True, header=0)
        self.validation_data = pd.read_csv(self.namefiles_dict["valid_filename"],
                                   index_col="time", parse_dates=True, header=0)

        self.train_labels = pd.read_csv(self.namefiles_dict["train_labl_filename"],
                                   index_col="time", parse_dates=True, header=0)
        self.test_labels = pd.read_csv(self.namefiles_dict["test_labl_filename"],
                                   index_col="time", parse_dates=True, header=0)
        self.validation_labels = pd.read_csv(self.namefiles_dict["valid_labl_filename"],
                                   index_col="time", parse_dates=True, header=0)

        # Todo: make this step unified and linked to instrument specific configuration
        # exctract relevant columns for training (features!)
        all_cols = self.train_data.columns
        for col in all_cols:
            if 'lag' in col:
                self.lagged_cols.append(col)

        # reorder features
        for lag in range(1, self.lags + 1):
            for feat in self.features:
                r = u.find_string(all_cols, feat + "_lag_" + str(lag))
                if r != -1:
                    self.lagged_cols_reordered.append(r)

        print("load_train_data: reordered features are:", self.lagged_cols_reordered)
        print("load_train_data: Lagged columns which are the input to the model:")
        print(self.lagged_cols)
        print("load_train_data: how many Lagged columns:")
        print(len(self.lagged_cols))
        print("self.train_data.head()\n",self.train_data.head())
        assert (not self.train_data[self.lagged_cols].isnull().values.any()), \
            "NANs in Training Data"
        assert (not self.train_labels["dir"].isnull().values.any()), \
            "NANs in LABELS"
        return # train and test data loaded. Validation carved out by Keras from training data

    def set_model(self):
        if self.model_id == "dnn1": # Todo: do this using the dictionary of models in model.py
            self.model = m.dnn1(dropout = True,
                              rate=0.1,
                              input_dim = len(self.lagged_cols))
        elif self.model_id == "LSTM_dnn":  #Todo: review if makes sense to inherit for each model...
            self.model = m.LSTM_dnn(dropout = 0.2,
                                    inputs = np.zeros((1, self.instrument_file .lags,
                                                       len(self.instrument_file .features))))
        elif self.model_id == "LSTM_dnn_all_states":  #Todo: review if makes sense to inherit for each model...
            self.model = m.LSTM_dnn_all_states(dropout = 0.2,
                                    inputs = np.zeros((1, self.instrument_file .lags,
                                                       len(self.instrument_file .features))))
        elif self.model_id == "ffn":
            self.model = m.ffn(self.train_data[self.lagged_cols],
                              rate=0.1)

        # visualize some details of the model NOT YET TRAINED
        # get some visualization before learning (on weights)
        # Todo: do this better to generate more informative insight
        # plt.hist(self.model.layers[2].get_weights()[0])
        # plt.show()
        # plt.figure()
        #
        # plt.hist(self.model.layers[2].get_weights()[1])
        # plt.show()
        # plt.figure()
        return

    def train_model(self, epochs=30):  # Todo: explode this using gradient_tape
        '''
        It trains the specified model on the training data already obtained
        '''
        if self.model_id == "ffn" or self.model_id == "ffn": #todo : do this better

            r = self.model.fit(x=self.train_data[self.lagged_cols],
                          y=self.train_labels["dir"],
                          epochs=epochs,
                          verbose=True,
                          validation_data=(self.validation_data[self.lagged_cols],
                                           self.validation_labels["dir"]),
                          shuffle=True,
                          batch_size=64,
                          class_weight=m.cw(self.train_labels))

        elif self.model_id == "LSTM_dnn" or \
                self.model_id ==  "LSTM_dnn_all_states":
            # inputs: A 3D tensor with shape [batch, timesteps, feature].

            numpy_train = trn._get_3d_tensor(
                self.train_data[self.lagged_cols_reordered].to_numpy(),
                    self.instrument_file)
            numpy_val = trn._get_3d_tensor(
                self.validation_data[self.lagged_cols_reordered].to_numpy(),
                    self.instrument_file)

            print("numpy_train.shape ",numpy_train.shape)

            r = self.model.fit(x = numpy_train,
                      y = self.train_labels["dir"].to_numpy(),
                      epochs = epochs,
                      verbose = True,
                      validation_data=(numpy_val,
                                       self.validation_labels["dir"].to_numpy()),
                      shuffle = True,
                      batch_size=64,  # Todo make BS a param
                      class_weight = m.cw(self.train_labels))

        # get some visualization of the effect of learning (on weights, loss, acc)
        # plt.hist(self.model.layers[2].get_weights()[0])
        # plt.show()
        # plt.figure()
        plt.plot(r.history['loss'], label="loss")
        plt.plot(r.history['val_loss'], label="val_loss")
        plt.legend()
        plt.show()
        plt.figure()
        plt.plot(r.history['acc'], label="acc")
        plt.plot(r.history['val_acc'], label="val_acc")
        plt.legend()
        plt.show()
        plt.figure()
        return

    @classmethod
    def _get_3d_tensor(cls, twodim_np_tensor, cfginst):
        return twodim_np_tensor.reshape(-1,
                                        cfginst.lags,
                                        len(cfginst.features))

    def save_model(self):
        model_folder = self.namefiles_dict["model_folder"]
        # Todo: save the model under folder for specific configuration (See conf_name under EUR_USD_1.py)
        if not os.path.exists(model_folder):
            logging.info("trainer: specific model folder does not exist: creating it...")
            os.mkdir(model_folder)
            # Todo add choice to break out?

        model_file_name = model_folder + "/" + str(self.model_id) + ".h5"
        self.model.save(model_file_name)

        print(model_file_name)
        return

    def evaluate_model(self):
        print("\n")
        if self.model_id == "ffn" or self.model_id == "ffn":  # todo : do this better

            print("main: Evaluating the model on in-sample data (training data)")
            self.model.evaluate(self.train_data[self.lagged_cols], self.train_labels["dir"], verbose=True)
            print("main: valuating the model on out-of-sample data (test data)")
            self.model.evaluate(self.test_data[self.lagged_cols], self.test_labels["dir"], verbose=True)

            # Todo: why evaluate does not show the accuracy?
        elif self.model_id == "LSTM_dnn" or \
                self.model_id ==  "LSTM_dnn_all_states":

            print("main: Evaluating the model on in-sample data (training data)")
            numpy_eval = self._get_3d_tensor(self.train_data[self.lagged_cols_reordered]. \
                to_numpy()) #.reshape(-1, cfginst.lags, len(cfginst.features))
            self.model.evaluate(numpy_eval, self.train_labels["dir"].to_numpy(), verbose=True)
            print("main: valuating the model on out-of-sample data (test data)")
            numpy_test = self._get_3d_tensor(self.test_data[self.lagged_cols_reordered]. \
                to_numpy()) #.reshape(-1, cfginst.lags, len(cfginst.features))
            self.model.evaluate(numpy_test, self.test_labels["dir"].to_numpy(), verbose=True)

        return

    def make_predictions(self):
        print("main: just testing predictions for later trading applications")
        if self.model_id == "ffn" or self.model_id == "ffn":  # todo : do this better
            pred = self.model.predict(self.train_data[self.lagged_cols], verbose=True)
        elif self.model_id == "LSTM_dnn" or \
                self.model_id ==  "LSTM_dnn_all_states":
            numpy_train = self._get_3d_tensor(self.train_data[self.lagged_cols_reordered]. \
                to_numpy())
            pred = self.model.predict(numpy_train, verbose=True)
        print(pred)
        return


################################ TRaDer (trd) class #########################################
class trd(ond, tpqoa.tpqoa):
    '''
    Trading class to get tick data and trade or to back/forward test using the data already obtained
    '''

    def __init__(self,
                 conf_file,
                 instrument_file,
                 model_id,
                 mu, std):

        tpqoa.tpqoa.__init__(conf_file)
        ond.__init__(instrument_file, conf_file)

        self.position = 0
        self.window = instrument_file.window
        self.bar_length = instrument_file.brl
        self.units = instrument_file.units
        self.model_id = model_id
        self.model = None
        self.mu = mu
        self.std = std
        self.tick_data = pd.DataFrame()
        self.hist_data = None
        self.min_length = None
        self.raw_data = None
        self.data = None
        self.profits = []
        self.half_spread = instrument_file.half_spread
        self.sma_int = instrument_file.sma_int
        self.features = instrument_file.features
        self.h_prob_th = instrument_file.higher_go_long
        self.l_prob_th = instrument_file.lower_go_short
        self.strategy = Strategy_1(instrument=self.instrument,
                                   order_fun= self.create_order,
                                   report_fun= self.report_trade)
        self.set_model()
        return


    def set_model(self):

        self.model = keras.models.load_model(cfg.trained_models_path +
                                        self.instrument + "/" + self.model_id + ".h5")
        print("Layers of model being used are: ")
        print(self.model.layers)
        return


    def test(self, data, labels):
        '''
        test the (model,strategy) pair on the passed, and compare the buy&hold with
        the chosen strategy. Ideally estimation of trading costs should be included
        '''

        test_outs = pd.DataFrame()
        self.data = data.copy()

        # Predictions
        test_outs["probs"] = self.predict(TESTING=True)

        # Strategy in action
        test_outs["position"] = self.strategy.act(
            prob_up=test_outs["probs"],
            thr_up=self.h_prob_th,
            thr_low=self.l_prob_th,
            live_or_test="test")

        # calculate Strategy Returns: I need access to returns here!!!
        # but likely the returns I have access here are standardized..
        # Todo: review how to grant access to returns here, and see if access to standardized is doable
        test_outs["strategy_gross"] = test_outs["position"] * \
                                      (data["returns"] * self.std["returns"]
                                                         + self.mu["returns"]) #de-standardizing
        # determine when a trade takes place
        test_outs["trades"] = test_outs["position"].diff().fillna(0).abs()
        # subtract transaction costs from return when trade takes place
        test_outs['strategy'] = test_outs["strategy_gross"] - test_outs["trades"] * self.half_spread
        # calculate cumulative returns for strategy & buy and hold
        test_outs["creturns"] = (data["returns"] * self.std["returns"]
                                 + self.mu["returns"]).cumsum().apply(np.exp)
        test_outs["cstrategy"] = test_outs['strategy'].cumsum().apply(np.exp)
        test_outs["cstrategy_gross"] = test_outs['strategy_gross'].cumsum().apply(np.exp)
        results = test_outs

        # absolute performance of the strategy
        perf = results["cstrategy"].iloc[-1]
        # out-/underperformance of strategy
        outperf = perf - results["creturns"].iloc[-1]
        print("outperf is ", outperf)

        # plot results
        # todo: review why figures are not shown as expected
        print("plotting cumulative results of buy&hold and strategy")
        title = "{} | Transaction Cost = {}".format(self.instrument, self.half_spread)
        results[["cstrategy",  "creturns", "cstrategy_gross"]].\
            plot(title=title, figsize=(12, 8))
        plt.show()
        plt.figure(figsize=(12, 8))
        plt.title("positions")
        #plt.plot(test_outs["trades"])
        plt.plot(test_outs["position"])
        plt.xlabel("time")
        plt.ylabel("positions")
        plt.show()

        return round(perf, 6), round(outperf, 6)


    def report_trade(self, order, going):
        print(order)
        time = order["time"]
        units = order["units"]
        # Todo: review this workaround to make it run as price and pl keys are missing sometimes
        print("order.keys(): ", order.keys())

        if "price" in order.keys():

            price = order["price"]
            pl = float(order["pl"])
            self.profits.append(pl)
            cumpl = sum(self.profits)

            print("\n" + 100 * "-")
            print("{} | {}".format(time, going))
            print("{} | units = {} | price = {} | P&L = {} | Cum P&L = {}".\
                  format(time, units, price, pl, cumpl))
            print(100 * "-" + "\n")
        return

    def get_most_recent(self, granul="S5", days = 2): #S5
        '''
        Get the most recent data for the instrument for which the object was created
        :param granul: base frequency for raw data being downloaded
        :param days: number of past days (from today) we are downloading data for
        '''
        # set start and end date for historical data retrieval
        now = datetime.utcnow()
        now = now - timedelta(microseconds = now.microsecond)
        past = now - timedelta(days = days)

        # get historical data up to now
        logging.info("get_most_recent: getting historical data from Oanda... ")
        df = pd.DataFrame()

        from threading import Thread, Event
        ask_df_got = Event()
        bid_df_got = Event()
        self.ask_df = pd.DataFrame()
        self.bid_df = pd.DataFrame()

        def ask_df_fun(ask_df_got,
                        instrument = self.instrument,
                        start = past,
                        end = now,
                        granularity = granul,
                        price = "A",
                        localize = False):

            self.ask_df = self.get_history(instrument=instrument,
                                      start=start,
                                      end=end,
                                      granularity=granularity,
                                      price=price,
                                      localize=localize).c.dropna().to_frame()
            ask_df_got.set()

        def bid_df_fun(bid_df_got,
                       instrument=self.instrument,
                       start=past,
                       end=now,
                       granularity=granul,
                       price="B",
                       localize=False):
            self.ask_df = self.get_history(instrument=instrument,
                                           start=start,
                                           end=end,
                                           granularity=granularity,
                                           price=price,
                                           localize=localize).c.dropna().to_frame()
            bid_df_got.set()

        # TODO: using default params above maybe all the params here are not needed, only event...
        # Create Threads
        t_ask = Thread(target=ask_df_fun(), args=(ask_df_got,
                                                  self.instrument,
                                                  past, now,
                                                  granul, "A", False))
        t_bid = Thread(target=bid_df_fun(), args=(bid_df_got,
                                                  self.instrument,
                                                    past, now,
                                                    granul,"B", False ))
        # Start Threads
        t_ask.start()
        t_bid.start()

        # wait for both threads to ahve collected data
        while not(ask_df_got and bid_df_got):
            pass

        # here both  self.ask_df and self.bid_df have been filled
        ask_df = self.ask_df # Todo correct this all with self
        bid_df = self.bid_df
        # make these 2 in separate threads and wait here, main thread, for completion of both
        # # each of the 2 thread will set an event, and when both are set, main thread continues
        # ask_df = self.get_history(instrument = self.instrument,
        #                             start = past,
        #                             end = now,
        #                             granularity = granul,
        #                             price = "A",
        #                             localize = False).c.dropna().to_frame()
        #
        # bid_df = self.get_history(instrument = self.instrument,
        #                             start = past,
        #                             end = now,
        #                             granularity = granul,
        #                             price = "B",
        #                             localize = False).c.dropna().to_frame()

        # combine price information to derive the spread
        for p in "ohlc":
            print(p)
            df['sprd_{}'.format(p)] = ask_df['{}'.format(p)] - bid_df['{}'.format(p)]
            df['ask_{}'.format(p)] = ask_df['{}'.format(p)]
            df['bid_{}'.format(p)] = bid_df['{}'.format(p)]
        df['volume'] = ask_df["volume"]
        df['c'] = (ask_df["c"] + ask_df['c'])/2
        df.rename(columns={"c": self.instrument}, inplace=True)

        print("\nhistory dataframe information:\n")
        df.info()

        logging.info("get_most_recent: resampling recent history to chosen bar length in line" +
                     " with the training data used to train the model")
        df = df.resample(self.bar_length, label="right").last().dropna().iloc[:-1]

        self.hist_data = df.copy()
        self.min_length = len(self.hist_data) + 1

        print("\nresampled history dataframe information:\n")
        df.info()
        return

    def resample_and_join(self):
        self.raw_data = self.hist_data.append(
                            self.tick_data.resample(self.bar_length,
                                    label="right").last().ffill().iloc[:-1])
        return

    def prepare_data(self):
        logging.info("\nprepare_data: creating features")

        # create base features
        df = self.raw_data.reset_index(drop=True, inplace=False)
        df = u.make_features(df,
                            self.sma_int,
                            self.window,
                            self.half_spread,
                            ref_price = self.instrument )

        # create lagged features
        df = u.make_lagged_features(df, self.features, self.lags)
        self.data = df.copy()

        return

    def predict(self, TESTING=False):
        print("\nSEQUENCE: predict")
        df = self.data.copy()
        if not TESTING:
            # if we are trading live (not TESTING) we need to normalize the data using
            # training dataset statistics
            df = (df - self.mu) / self.std
        # get feature columns
        all_cols = self.data.columns
        lagged_cols = []
        lagged_cols_reordered = []


        if self.model_id == "ffn" or self.model_id == "ffn":
            for col in all_cols:
                if 'lag' in col:
                    lagged_cols.append(col)
            df["proba"] = self.model.predict(df[lagged_cols])

        elif self.model_id == "LSTM_dnn":
            # reoder features
            for lag in range(1, self.lags + 1):
                for feat in self.features:
                    r = u.find_string(all_cols, feat + "_lag_" + str(lag))
                    if r != -1:
                        lagged_cols_reordered.append(r)

            numpy_train = self._get_3d_tensor(df[lagged_cols_reordered]. \
                to_numpy())
            df["proba"] = self.model.predict(numpy_train, verbose=True)

        self.data = df.copy()
        if TESTING:
            return df["proba"]
        else:
            return

    def _get_3d_tensor(self, twodim_np_tensor):
            return twodim_np_tensor.reshape(-1,
                                            self.instrument_file.lags,
                                            len(self.instrument_file.features))

    def on_success(self, time, bid, ask):
        print("\nReceived ticks: ", self.ticks, end=" ")

        # store and resample tick data and join with historical data
        ask_df = pd.DataFrame({self.instrument: ask },
                          index=[pd.to_datetime(time)])
        bid_df = pd.DataFrame({self.instrument: bid},
                              index=[pd.to_datetime(time)])

        # visualize the data added to the tick_data
        print("on_success: adding to tick_data: {} []".format(ask_df, bid_df))
        self.tick_data = self.tick_data.append(
                            pd.concat([ask_df, bid_df], axis=1, join='inner'))
        print("self.tick_data.head()\n", self.tick_data.head())

        self.resample_and_join()

        # only if new bar has been added:
        if len(self.raw_data) > self.min_length - 1:
            self.min_length += 1
            self.prepare_data()
            self.predict()
            print("on_success: predicted probabilty for next bar is ", self.data["proba"].iloc[-1])
            # orders and trades
            # here we apply a strategy based on the probabilities. Many strategies are possible
            # Todo: externalize the strategy and make this class support historical data, for backtesting purposes
            # from functool import partial
            self.position = self.strategy.act(
                       position=self.position,
                       prob_up=self.data["proba"].iloc[-1],
                       thr_up=self.h_prob_th,
                       thr_low=self.l_prob_th,
                       units = self.units,
                       live_or_test="live")
        return


################################################## ctrl ###############################################
class ctrl:
    '''
    Class for controlling data acquisition, model training, testing and trading of
    ML based trading strategies
    '''

    def __init__(self,
                 conf_file, # oanda user conf file
                 instrument_files):  # list of instrument conf files - for now only 1 element supported!

        self.instrument_files = instrument_files
        self.instruments = [t.instrument for t in self.instrument_files]
        self.labels = [t.labels for t in self.instrument_files]  # "dir", "profit_over_spread", "loss_over_spread"]
        self.features = [t.features for t in self.instrument_files]
        self.lags = [t.lags for t in self.instrument_files]

        self.namefiles_dicts = []
        for f in self.instrument_files:
            namefiles_dict = {}
            namefiles_dict = u.creates_filenames_dict(
                f.instrument,
                namefiles_dict, cfg)
            self.namefiles_dicts.append(namefiles_dict)

        # Create the first of the fundamental objects to operate:
        # getting data.
        # train model, test and trade, will be created later, when clarified
        # if we have all the necessary parts (data, mu, std at least)

        # many objects to get data? or just one that deals internally with multithread.
        # for now make many
        self.gdt_list = []
        for f in instrument_files:
            b = gdt(f, conf_file)
            self.gdt_list.append(b)

        return

        # # many objects to train the model on a specific data and targets
        # self.model_id = model_id
        # self.trn_list = []
        # for f in instrument_files:
        #     b = trn(f, conf_file, self.model_id)
        #     self.trn_list.append(b)
        #
        # # only one trader is needed, as it will take a model trained on the joint data
        # # and it will get tick data from a set of threads, one for each instrument, and t
        # # the model can have multiple outputs predicting the market trend for each instrument
        # # for now trader supports only one instrument however so let's pass the first in the list
        #
        # self.trader = trd(self.instrument_files[0], conf_file,
        # return